{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "immobiliare.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO05+D+4UCkEBoSbJGmFlfe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinansonmez/Coursera_Capstone/blob/master/immobiliare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU63yyYLHMj9",
        "outputId": "3ad7317c-65fb-4b06-f11b-859c7d0cc332",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import requests\n",
        "from urllib.request import urlopen\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install bs4\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPbOs7v7Hg0f"
      },
      "source": [
        "# Use the requests library to download the webpage\n",
        "base_url = \"https://www.immobiliare.it/vendita-case/\"\n",
        "municipality = \"lainate\"\n",
        "page = \"/?pag=\"\n",
        "url = base_url + municipality\n",
        "my_headers = {\n",
        "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.1 Safari/605.1.15',\n",
        "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'\n",
        "}\n",
        "\n",
        "html_data = requests.get(url, headers=my_headers).text"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gb0PWzyId33"
      },
      "source": [
        "# Parse the html data using beautiful_soup\n",
        "soup = BeautifulSoup(html_data, \"html5lib\")\n",
        "page_num = soup.find_all('li', class_='disabled')[-1].text"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKqK_jf-I3sU"
      },
      "source": [
        "# Using beautiful soup extract the table and store it into a dataframe named istanbul_data. \n",
        "# The dataframe have columns. Fill in each variable with the correct data from the list cell.\n",
        "\n",
        "real_estate_data = pd.DataFrame(columns=['id', 'title', 'price', 'room', 'sqm', 'bagni', 'piano', 'link'])\n",
        "\n",
        "# for each page get the data and append to real_estate_data\n",
        "for num in range(1, int(page_num) + 1):\n",
        "  url_page_num = base_url + municipality + page + str(num)\n",
        "  soup = BeautifulSoup(urlopen(url_page_num), \"html5lib\")\n",
        "\n",
        "  list = soup.find_all('div', class_='listing-item_body--content')\n",
        "\n",
        "  for item in list:\n",
        "    title = item.find('p').text.replace('\\n','')\n",
        "    link = item.find('a').get('href').replace('\\n','')\n",
        "    id = link.split('/')[4]\n",
        "    for detail in item.find_all('li'):\n",
        "      if (detail.text.find('€') != -1):\n",
        "        price = detail.text.replace('€ ','').replace('.','').replace(' ','').replace('da','').replace('\\n','')\n",
        "      if (detail.text.find('locali') != -1):\n",
        "        room = detail.text.replace(' ', '').replace('locali', '').replace('\\n','')\n",
        "      if (detail.text.find('superfici') != -1):\n",
        "        sqm = detail.text.replace('m2superficie', '').replace('\\n','')\n",
        "      if (detail.text.find('bagni') != -1):\n",
        "        bagni = detail.text.replace('bagni', '').replace('\\n','')\n",
        "      if (detail.text.find('piano') != -1):\n",
        "        piano = detail.text.replace('piano', '').replace('\\n','')\n",
        "    \n",
        "    real_estate_data = real_estate_data.append({'id':id, 'title': title, 'price': price, 'room': room, 'sqm': sqm, 'bagni': bagni, 'piano': piano, 'link': link}, ignore_index=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lng3Lmr1x887"
      },
      "source": [
        "# real_estate_data\n",
        "real_estate_data.to_csv('real_estate_data.csv', index=False)"
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}